---
title: "Baseline exploration"
output:
  html_document:
    df_print: paged
---

+ Different radius - pandas_haversine_distance() & calc_haversine(). Could just use geosphere::distHaversine()? 
+ Closer points seems to jitter 

```{r eval=FALSE, include=FALSE}
# This is to make a baseline. Same code as here, just written in R. <https://www.kaggle.com/code/saitodevel01/gsdc2-baseline-submission> And here: <https://www.kaggle.com/code/ravishah1/gsdc2-savgol-filter-outlier-removal-with-bo>

# Get base station observations: <https://www.ngs.noaa.gov/UFCORS/> Navigation data for GNSS constellations: <https://igs.bkg.bund.de/root_ftp/IGS/BRDC/>

# Look for smoothing techniques
# other interpolation methods - for NAs
# integrating IMU and gnss
```

```{r Setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, warning = FALSE, error = FALSE, message = FALSE, tidy = TRUE, fig.dim = c(10, 6), global.par = TRUE)
```

```{r}
library(tidyverse)
library(data.table)

source("baseline_functions.R")
source("helper_functions.R")
source("outliers_and_smoothing.R")
```

Raw score
```{r open data}
blh_df = read_rds( "data/train/cleaned_to_blh.rds")

# select one phone
trip_ids = unique(blh_df$tripID)[46]
gt = open_gt(trip_ids)
raw_df = blh_df[tripID == trip_ids]
calc_score(trip_ids, raw_df)
```

Score with savgol smoothing
```{r after smoothing}
pred_df = correct_outliers(raw_df, 2.3059423828286683) #|> setDT() # ??
pred_df = apply_savgol_filter(tripID, df = pred_df, wl = 9, 2)
calc_score(trip_ids, pred_df)
```

```{r get score, eval=FALSE, include=FALSE}
# baseline score
scores = purrr::map_df(trip_ids, calc_score, pred_df = blh_df)
mean(scores$score) # 4.356924
```



```{r eval=FALSE, include=FALSE}
ggplot(pred_df) +
  geom_point(aes(x = LatitudeDegrees, y = LongitudeDegrees ), color = "red") +
  geom_point(data = gt_df, aes(x = LatitudeDegrees, y = LongitudeDegrees), color = "green", size = .5)
```

Plot of raw (blue) vs smoothed (green) vs ground truth (red)

```{r map them}
library(mapview)

pred_sf = sf::st_as_sf(
    x = pred_df,
    coords = c("LongitudeDegrees", "LatitudeDegrees"),
    crs = 4326,
    na.fail = FALSE
  )
raw_sf = sf::st_as_sf(
    x = raw_df,
    coords = c("LongitudeDegrees", "LatitudeDegrees"),
    crs = 4326,
    na.fail = FALSE)

gt_sf = sf::st_as_sf(
    x = gt,
    coords = c("LongitudeDegrees", "LatitudeDegrees"),
    crs = 4326,
    na.fail = FALSE
  )
mapviewOptions(basemaps = c('Esri.WorldImagery'))
mapview::mapview(pred_sf, col.regions = "green") + mapview(gt_sf, col.regions = "red") + mapview(raw_sf, col.regions = "blue")
```

```{r eval=FALSE, include=FALSE}
# I don't know why this doesn't work in R
optimize <- function(threshold, window_len, poly_order) {
  # optimize <- function(params) {
  # threshold = unlist(threshold)
  # window_len = unlist(window_len)
  # poly_order = unlist(poly_order)
  # message(params[threshold])
  # params['threshold']
  # threshold |> unlist()
  # print(threshold)
  # params$threshold
  # window_len = as.integer(window_len)
  # must be odd
  # if (window_len %% 2 == 0) {
  #   window_len = window_len + 1
  # }
  return(3)
}
# https://rpubs.com/Argaadya/bayesian-optimization
space1 = tuple(threshold = c(1.5, 2.5), 
         window_len = c(7, 31),
         poly_order = c(2, 6))
search_grid <- data.frame(threshold = runif(20,1.5,2.5),
                          window_len = runif(20,7,31),
                          poly_order = runif(20,2,6))
rBayesianOptimization::BayesianOptimization(FUN = optimize, bounds = space, init_grid_dt = search_grid, n_iter = 2)
library(reticulate)
py$result$x
optimize(list(1.88, 13, 4))
py$gp_minimize(optimize, r_to_py(space1), n_cblh_dfs=10)

py_to_r(py$space)
```

```{python eval=FALSE, include=FALSE}
from skopt import gp_minimize
from skopt.space import Real, Integer

space = [Real(1.5, 2.5, name='threshold'), 
         Integer(7, 31, name='window_len'), 
         Integer(2, 6, name='poly_order')]

result = gp_minimize(r.optimize, space, n_calls=10) # works!
result

# Make sure wl is odd, wl be > than poly
if result.x[1]%2==0:
    result.x[1]+=1

print(f'best params:\noutlier threshhold: {result.x[0]}\nsavgol filter window length: {result.x[1]}\nsavgol filter poly order: {result.x[2]}')
result.x
result.fun
# for blh_df score 3.935 [2.3059423828286683, 9, 2]
```

```{r eval=FALSE, include=FALSE}
# let's apply this optimize parameters
threshold = 2.3059423828286683
window_len = 9
poly_order = 2
score_list = data.frame()

  for (i in 1:length(trip_ids)) {
    trip = trip_ids[i]
    
    pred_df = blh_df[tripID == trip]
    
    # We are using BLH, not ECEF to optimize
    pred_df = correct_outliers(pred_df, threshold) |> setDT() # ??
    pred_df = apply_savgol_filter(tripID, df = pred_df, wl = window_len, poly_order)
    # print(pred_df)
    score = calc_score(trip, pred_df)
    score_list = bind_rows(score_list, score)
  }
mean(score_list$score) # 3.934705
```
