---
title: "Baseline exploration"
output:
  html_document:
    df_print: paged
---

+ Different radius - pandas_haversine_distance() & calc_haversine(). Could just use geosphere::distHaversine()? 
+ Closer points seems to jitter 
+ use geosphere::distVincentyEllipsoid over halversine? 

Based on: https://www.kaggle.com/code/taroz1461/carrier-smoothing-robust-wls-kalman-smoother

```{r eval=FALSE, include=FALSE}
# This is to make a baseline. Same code as here, just written in R. <https://www.kaggle.com/code/saitodevel01/gsdc2-baseline-submission> And here: <https://www.kaggle.com/code/ravishah1/gsdc2-savgol-filter-outlier-removal-with-bo>

# Get base station observations: <https://www.ngs.noaa.gov/UFCORS/> Navigation data for GNSS constellations: <https://igs.bkg.bund.de/root_ftp/IGS/BRDC/>

# Look for smoothing techniques
# other interpolation methods - for NAs
# integrating IMU and gnss
```

```{r Setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, warning = FALSE, error = FALSE, message = FALSE, tidy = TRUE, fig.dim = c(10, 6), global.par = TRUE)
```

```{r}
library(tidyverse)
library(data.table)
library(reticulate)

source("baseline_functions.R")
source("helper_functions.R")
# source("outliers_and_smoothing.R")

# Constants
CLIGHT = 299792458   # speed of light (m/s)
RE_WGS84 = 6378137   # earth semimajor axis (WGS84) (m)
OMGE = 7.2921151467E-5  # earth angular velocity (IS-GPS) (rad/s)
```

```{python}
from scipy.optimize import least_squares
import numpy as np
```

Raw score
```{r open data}
# blh_df = read_rds( "data/train/cleaned_to_blh.rds")

# trip_ids = unique(blh_df$tripID)#

# select one phone
one_trip ="2020-05-21-US-MTV-2/GooglePixel4XL"#  trip_ids[5]
path = "data/train/"
gnss_df = read.csv(paste0(path, one_trip, "/device_gnss.csv")) |> setDT()

# gt = open_gt(trip_ids)
# raw_df = blh_df[tripID == trip_ids]
# calc_score(trip_ids, raw_df)
```

```{r satellite selection}
# Satellite selection using carrier frequency error, elevation angle, and C/N0
satellite_selection <- function(gnss_df, column) {
    "Args:
        df : DataFrame from device_gnss.csv
        column : Column name
    Returns:
        df: DataFrame with eliminated satellite signals"

  match = which(!is.na(gnss_df[[column]]) &
                  gnss_df[["SvElevationDegrees"]] > 10.0 &
                  gnss_df[["Cn0DbHz"]] > 15.0 &
                  gnss_df[["CarrierErrorHz"]] < 2.0e6 &
                  gnss_df[["MultipathIndicator"]] == 0,
                arr.ind = T)
  
  # Returns matching row
  return(gnss_df[match])
}
```

```{r residuals and jacobian}
# Compute line-of-sight vector from user to satellite

# Returns XYZ and rng

los_vector <- function(xusr, xsat) {
  "
    Args:
        xusr : user position in ECEF (m)
        xsat : satellite position in ECEF (m)
    Returns:
        u: unit line-of-sight vector in ECEF (m)
        rng: distance between user and satellite (m)
    "
  # Take inverse of xsat
  # m = as.matrix(xusr - xsat, ncol = 3)
  m = sweep(xsat, 2, -xusr) # I think it should be negative?
  rng = apply(m, 1, pracma::Norm) |> matrix(ncol = 1)
  # |>  matrix(dimnames=list(t(outer(colnames(m), rownames(m), FUN=paste)), NULL))
  
  m = m / cbind(rng, rng, rng)
  m = cbind(m, rng)
  colnames(m) <-
    c(
      "SvPositionXEcefMeters",
      "SvPositionYEcefMeters" ,
      "SvPositionZEcefMeters",
      "rng"
    )
  return(m)
}
```

```{r jacobian}
# Compute Jacobian matrix
# TODO haystack?
jac_pr_residuals <- function(x, xsat, pr, W) {
  "
    Args:
        x : current position in ECEF (m)
        xsat : satellite position in ECEF (m)
        pr : pseudorange (m)
        W : weight matrix
    Returns:
        W*J : Jacobian matrix
    "
  u = los_vector(x[1:3], xsat)
  u = u[, 1:3]
  J = cbind(u, rep(1, nrow(u)))
  
  # return(array(W %*% J))
  return(as.matrix(W %*% J, ncol = 4))
}

# Compute pseudorange residuals
pr_residuals <- function(x, xsat, pr, W) {
  "Args:
        x : current position in ECEF (m)
        xsat : satellite position in ECEF (m)
        pr : pseudorange (m)
        W : weight matrix
    Returns:
        residuals*W : pseudorange residuals"
  
  rng = los_vector(x[1:3], xsat)[, 4]
  # Approximate correction of the earth rotation (Sagnac effect) often used in GNSS positioning
  # Formula: OMGE * (Y*0 - X*0) / CLIGHT - add this to rng
  
  to_add = rng + (OMGE * (xsat[, 1] * x[2] - xsat[, 2] * x[1]) / CLIGHT)
  residuals = to_add - (pr - x[4])
  
  return(array(W %*% residuals))
}

# Compute Jacobian matrix
jac_prr_residuals <- function(v, vsat, prr, x, xsat, W) {
  "Args:
        v : current velocity in ECEF (m/s)
        vsat : satellite velocity in ECEF (m/s)
        prr : pseudorange rate (m/s)
        x : current position in ECEF (m)
        xsat : satellite position in ECEF (m)
        W : weight matrix
    Returns:
        W*J : Jacobian matrix"
  u = los_vector(x[1:3], vsat)
  J = cbind(u[, 1:3], rep(1, nrow(u)))
  # return(array(W %*% J))
  return(as.matrix(W %*% J, ncol = 4))
}

# Compute pseudorange rate residuals
prr_residuals <- function(v, vsat, prr, x, xsat, W) {
  "
    Args:
        v : current velocity in ECEF (m/s)
        vsat : satellite velocity in ECEF (m/s)
        prr : pseudorange rate (m/s)
        x : current position in ECEF (m)
        xsat : satellite position in ECEF (m)
        W : weight matrix
    Returns:
        residuals*W : pseudorange rate residuals
    "
  # u is XYZ then rng
  u = los_vector(x[1:3], xsat)[,1:3]
  # print(rowSums((vsat[, 1:3] - v[1:3])))
  # print(vsat[, 1:3] - v[1:3] )
  # print(sweep(vsat[ , 1:3], 2, - v[1:3])*u)
  rate = rowSums(sweep(vsat[ , 1:3], 2, - v[1:3])*u) +
    OMGE / CLIGHT * (vsat[, 2] * x[1] + xsat[, 2] * v[1] - vsat[, 1] * x[2] - xsat[, 1] * v[2]) |> as.matrix()
  
  residuals = rate - (prr - v[4])
  residuals = as.array(residuals[, 1])
  
  return(array(residuals %*% W))
  
}
```

```{r smoothing}
  carr_th = 2.0 # carrier phase jump threshold [m]
  pr_th =  20.0 # pseudorange jump threshold [m]
# Carrier smoothing of pseudarange
carrier_smoothing <- function(gnss_df) {
  "Args:
        df : DataFrame from device_gnss.csv
    Returns:
        df: DataFrame with carrier-smoothing pseudorange 'pr_smooth'"
  # carr_th = 2.0 # carrier phase jump threshold [m]
  # pr_th =  20.0 # pseudorange jump threshold [m]
  
  # prsmooth = np.full_like(gnss_df['RawPseudorangeMeters'], np.nan)
  # prsmooth = array(rep(NA, nrow(gnss_df))) # nrow array of NAs
  gnss_df[, idx := 1:nrow(gnss_df)]
  unique_svid_signal = group_by(gnss_df, Svid, SignalType) |> count() #|> head(3)
  # Loop for each signal
  with_smoothing = purrr::map2_df(
    unique_svid_signal[["Svid"]],
    unique_svid_signal[["SignalType"]],
    smooth_range,
    df_orig = gnss_df,
    prsmooth = prsmooth
  )
  gnss_df = left_join(gnss_df, with_smoothing, by = "idx")
  
  # If carrier smoothing is not possible, use original pseudorange
  gnss_df[, prsmooth := ifelse(is.na(prsmooth), RawPseudorangeMeters, prsmooth)]
  # gnss_df['pr_smooth'] = prsmooth
  
  return(gnss_df)
}
```

```{r}
smooth_range <- function(svid, signal_type, df_orig, prsmooth)
{
  df = df_orig[Svid == svid & SignalType == signal_type]
  # df = df.replace({'AccumulatedDeltaRangeMeters': {0: np.nan}})  # 0 to NaN
  df[, AccumulatedDeltaRangeMeters := ifelse(AccumulatedDeltaRangeMeters ==
                                               0 ,
                                             NA,
                                             AccumulatedDeltaRangeMeters)]# 0 to NaN
  
  # Compare time difference between pseudorange/carrier with Doppler
  drng1 = ave(
    df[["AccumulatedDeltaRangeMeters"]],
    FUN = function(x)
      c(NA, diff(x))
  ) - df[, 'PseudorangeRateMetersPerSecond']
  drng2 = ave(
    df[["RawPseudorangeMeters"]],
    FUN = function(x)
      c(NA, diff(x))
  ) - df[, 'PseudorangeRateMetersPerSecond']
  
  # Check cycle-slip
  slip1 = sapply(df[['AccumulatedDeltaRangeState']], bitwAnd, b = 2**1) != 0 # reset flag
  slip2 = sapply(df[['AccumulatedDeltaRangeState']], bitwAnd, b = 2**2) != 0 # cycle-slip flag
  slip3 = abs(drng1[['PseudorangeRateMetersPerSecond']]) > carr_th  # Carrier phase jump
  slip4 = abs(drng2[["PseudorangeRateMetersPerSecond"]]) > pr_th # Pseudorange jump
  
  idx_slip = slip1 | slip2 | slip3 | slip4
  idx_slip[1] = TRUE
  
  # change NA to FALSE
  idx_slip[is.na(idx_slip)] <- FALSE
  
  # groups with continuous carrier phase tracking
  # add column of cumsum
  df[, group_slip := cumsum(idx_slip)]
  
  # Psudorange - carrier phase
  df[, dpc := RawPseudorangeMeters - AccumulatedDeltaRangeMeters]
  
  # Absolute distance bias of carrier phase
  mean_dpc = df [, .(dpc_Mean = mean(dpc)), by = group_slip]
  df = merge(df, mean_dpc, by = "group_slip")
  
  # Carrier phase + bias
  df[, prsmooth := AccumulatedDeltaRangeMeters + dpc_Mean]

  return(df[, .(idx, prsmooth)])
}
```

```{r}
# GNSS single point positioning using pseudorange
point_positioning <- function(gnss_df){
  # Add nominal frequency to each signal
  # Note: GLONASS is an FDMA signal, so each satellite has a different frequency
    hz_ref = gnss_df[ , list(CarrierFrequencyHzRef=median(CarrierFrequencyHz)), by=.(Svid, SignalType)]
    
    gnss_df = left_join(gnss_df, hz_ref, by = c("Svid", "SignalType"))
    gnss_df[ , "CarrierErrorHz" := abs(CarrierFrequencyHz - CarrierFrequencyHzRef) ]
    
    # Carrier smoothing
    gnss_df = carrier_smoothing(gnss_df)

    # GNSS single point positioning
    utcTimeMillis = unique(gnss_df[["utcTimeMillis"]])
    nepoch = length(utcTimeMillis)
    x0 <<- c(rep(0, 4))  # [x,y,z,tGPSL1]
    x0 <<-np_array(x0)
    v0 <<- c(rep(0, 4))  # [vx,vy,vz,dtGPSL1]
    v0 <<- np_array(v0)
    
    x_wls = matrix(NA, nrow = nepoch, ncol = 4) # For saving position
    v_wls = matrix(NA, nrow = nepoch, ncol = 4) # For saving velocity
    cov_x <<- array(NA,dim=c(4, 4, nepoch))
    cov_y <<- array(NA,dim=c(4, 4, nepoch))
    # nepoch = 100
    # Loop for epochs 
    for (i in 1:nepoch) {
      # print(utcTimeMillis[i]) # the time
      # print(i)
      
      # df = gnss_df[utcTimeMillis == 1590097058443]
      df = gnss_df[utcTimeMillis == utcTimeMillis[i]]
      # for i, (t_utc, df) in enumerate(tqdm(gnss_df.groupby('utcTimeMillis'), total=nepoch)):
      # Valid satellite selection
      df_pr <<- satellite_selection(df, 'prsmooth')
      df_prr <<- satellite_selection(df, 'PseudorangeRateMetersPerSecond')
      
      # Corrected pseudorange/pseudorange rate
      pr <<- (df_pr[['prsmooth']] + df_pr[['SvClockBiasMeters']] - df_pr[['IsrbMeters']] -
              df_pr[['IonosphericDelayMeters']] - df_pr[['TroposphericDelayMeters']])
      prr <<- (df_prr[['PseudorangeRateMetersPerSecond']] +
               df_prr[['SvClockDriftMetersPerSecond']])
      
      # Satellite position/velocity
      xsat_pr <<- as.matrix(df_pr[, list(SvPositionXEcefMeters,
                                       SvPositionYEcefMeters,
                                       SvPositionZEcefMeters)])
      xsat_prr <<- as.matrix(df_prr[, list(SvPositionXEcefMeters,
                                         SvPositionYEcefMeters,
                                         SvPositionZEcefMeters)])
      vsat <<- as.matrix(df_prr[, list(
        SvVelocityXEcefMetersPerSecond,
        SvVelocityYEcefMetersPerSecond,
        SvVelocityZEcefMetersPerSecond
      )])
      
      # Weight matrix for peseudorange/pseudorange rate
      Wx <<- diag(1 / df_pr[['RawPseudorangeUncertaintyMeters']])
      Wv <<- diag(1 / df_pr[['PseudorangeRateUncertaintyMetersPerSecond']])
      
      # Robust WLS requires accurate initial values for convergence,
      # so perform normal WLS for the first time
      # if (length(df_pr) >= 4){}
      source_python("optimize_ls.py") # new x0 and cov
      cov_x[, , i] = cov
      x_wls[i, ] = opt$x
      x0 = opt$x
      
      source_python("optimize_ls_prr.py")
      cov_y[, , i] = cov_prr
      v_wls[i, ] = opt_prr$x
      v0 = opt_prr$x
    }
    # return(utcTimeMillis, x_wls, v_wls, cov_x, cov_y)
    x = cbind(matrix(utcTimeMillis), x_wls, v_wls)
    return(list(x, cov_x, cov_y))
    # return(x)
}
gnss_df = read.csv(paste0(path, one_trip, "/device_gnss.csv")) |> setDT()
# gnss_df = gnss_df[1:500]
pp = point_positioning(gnss_df)
pp
# (time, x,y,z, rng, x, y, z, rng), cov_x, cov_y
# write_rds(pp, "pp.rds")
# They all work
# pr_residuals(x0, xsat_pr, pr, Wx)
# jac_pr_residuals(x0, xsat_pr, pr, Wx)
# prr_residuals(v0, vsat, prr, x0, xsat_prr, Wv)
# jac_prr_residuals(v0, vsat, prr, x0, xsat_prr, Wv)
# pracma::jacobian(pr_residuals , x0, xsat = xsat_pr, pr = pr, W = Wx) # same as jac_pr_res
```

```{python kalman}
def Kalman_filter(zs, us, cov_zs, cov_us, phone):
    # Parameters
    sigma_mahalanobis = 30.0  # Mahalanobis distance for rejecting innovation

    n, dim_x = zs.shape
    F = np.eye(3)  # Transition matrix
    H = np.eye(3)  # Measurement function

    # Initial state and covariance
    x = zs[0, :3].T  # State
    P = 5.0**2 * np.eye(3)  # State covariance
    I = np.eye(dim_x)

    x_kf = np.zeros([n, dim_x])
    P_kf = np.zeros([n, dim_x, dim_x])

    # Kalman filtering
    for i, (u, z) in enumerate(zip(us, zs)):
        # First step
        if i == 0:
            x_kf[i] = x.T
            P_kf[i] = P
            continue

        # Prediction step
        Q = cov_us[i] # Estimated WLS velocity covariance
        x = F @ x + u.T
        P = (F @ P) @ F.T + Q

        # Check outliers for observation
        d = distance.mahalanobis(z, H @ x, np.linalg.inv(P))

        # Update step
        if d < sigma_mahalanobis:
            R = cov_zs[i] # Estimated WLS position covariance
            y = z.T - H @ x
            S = (H @ P) @ H.T + R
            K = (P @ H.T) @ np.linalg.inv(S)
            x = x + K @ y
            P = (I - (K @ H)) @ P
        else:
            # If observation update is not available, increase covariance
            P += 10**2*Q

        x_kf[i] = x.T
        P_kf[i] = P

    return x_kf, P_kf


# Forward + backward Kalman filter and smoothing
def Kalman_smoothing(x_wls, v_wls, cov_x, cov_v, phone):
    n, dim_x = x_wls.shape

    # For some unknown reason, the speed estimation is wrong only for XiaomiMi8
    # so the variance is increased
    if phone == 'XiaomiMi8':
        v_wls = np.vstack([(v_wls[:-1, :] + v_wls[1:, :])/2, np.zeros([1, 3])])
        cov_v = 1000.0**2 * cov_v
         
    # Forward
    v = np.vstack([np.zeros([1, 3]), (v_wls[:-1, :] + v_wls[1:, :])/2])
    x_f, P_f = Kalman_filter(x_wls, v, cov_x, cov_v, phone)

    # Backward
    v = -np.flipud(v_wls)
    v = np.vstack([np.zeros([1, 3]), (v[:-1, :] + v[1:, :])/2])
    cov_xf = np.flip(cov_x, axis=0)
    cov_vf = np.flip(cov_v, axis=0)
    x_b, P_b = Kalman_filter(np.flipud(x_wls), v, cov_xf, cov_vf, phone)

    # Smoothing
    x_fb = np.zeros_like(x_f)
    P_fb = np.zeros_like(P_f)
    for (f, b) in zip(range(n), range(n-1, -1, -1)):
        P_fi = np.linalg.inv(P_f[f])
        P_bi = np.linalg.inv(P_b[b])

        P_fb[f] = np.linalg.inv(P_fi + P_bi)
        x_fb[f] = P_fb[f] @ (P_fi @ x_f[f] + P_bi @ x_b[b])

    return x_fb, x_f, np.flipud(x_b)
  
  # utc, x_wls, v_wls, cov_x, cov_v = pp
x_kf, _, _ = Kalman_smoothing(x_wls, v_wls, cov_x, cov_v, "PixelXL")

x_wls = np.array(r.pp[2])
v_wls = np.array(r.pp[3])
cov_x = np.array(r.pp[2])
cov_v = np.array(r.pp[3])
```

```{r}
library(reticulate)
lapply(list(x0, xsat_pr, pr, Wx), class)

py$least_squares(pr_residuals, x0_v, args= c(xsat_pr, pr_l, Wx))

source_python("optimize_ls.py")
gslnls::gsl_nls(pr_residuals(x0, xsat_pr, pr_l, Wx))
```

```{python}
r.Wx
# list nparray list nparray
type(r.Wx)
from scipy.optimize import least_squares
import numpy as np
# wls = least_squares
# import scipy
ls = least_squares(r.pr_residuals, r.x0, r.jac_pr_residuals, args=(r.xsat_pr, r.pr, r.Wx))
x02 = ls.x
# r.jac_pr_residuals(r.x0, r.xsat_pr, r.pr, r.Wx)
# r.pr_residuals(r.x0, r.xsat_pr, r.pr, r.Wx)
# r.prr_residuals(r.v0, r.vsat, r.prr, r.x0, r.xsat_prr, r.Wv)
# r.jac_prr_residuals(r.v0, r.vsat, r.prr, r.x0, r.xsat_prr, r.Wv)
```

```{r}
# R gets aborted
# KalmanSmooth(gnss_df$WlsPositionXEcefMeters, mod = list("a", "Pn"))
```

```{r get score, eval=FALSE, include=FALSE}
# baseline score
scores = purrr::map_df(trip_ids, calc_score, pred_df = blh_df)
mean(scores$score) # 4.356924
```

```{r}
library(KFAS) # Also FKF
# https://cran.r-project.org/web/packages/KFAS/KFAS.pdf
# https://cran.r-project.org/web/packages/KFAS/vignettes/KFAS.pdf
t = trip_ids[45]
x = blh_df[tripID == t]
open_gt(t)
calc_score(t, blh_df)
# minimize this
d = pandas_haversine_distance(x, open_gt(t))
mean(c(quantile(d, .5, na.rm = T), quantile(d, .95, na.rm = T)), na.rm = T)

KFS(SSModel(d ~ x$LatitudeDegrees + x$LongitudeDegrees, blh_df))

pp_df = pp |> as.data.frame()
# SSModel(formula, data, H, u, distribution, tol = .Machine$double.eps^0.5)
KFS(KFAS::SSModel(formula = V5 ~ V2 + V1, data = pp_df))

xv = pp[[1]]
x = xv[, 2:5]
v = xv[, 6:9]
cov_x = pp[[2]]
cov_v = pp[[3]]
cov_x |> class()
cov_x
source_python("kalman_filter.py")
py$Kalman_filter(x_wls, v_wls, cov_x, cov_v, "phone")
py$Kalman_filter(x, v, pp[[2]], pp[[3]], "phone")
```


```{r}
source_python("interpolate_outlier.py")
py$exclude_interpolate_outlier(x, v, cov_x, cov_v)
```

```{python}
exclude_interpolate_outlier(r.x, r.v, r.cov_x, r.cov_v)
import pymap3d as pm
r.cov_x.shape
np.full([5, 3, 3], np.nan)
```


